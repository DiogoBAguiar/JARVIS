# J.A.R.V.I.S. (Just A Rather Very Intelligent System)
### Arquitetura Cognitiva Modular HÃ­brida com VisÃ£o Computacional

O **J.A.R.V.I.S.** Ã© um assistente pessoal avanÃ§ado, projetado com uma arquitetura biomimÃ©tica inspirada no cÃ©rebro humano. Diferente de bots lineares, ele opera sobre um **Barramento de Eventos (Event-Driven)**, permitindo processamento assÃ­ncrono, resiliÃªncia a falhas e raciocÃ­nio hÃ­brido (Nuvem + Local).

O sistema integra LLMs modernos (Llama 3 via Groq e Ollama Local), VisÃ£o Computacional e controlo de sistema operacional, orquestrados por um Kernel em Python.

---

## ğŸ§  Arquitetura do Sistema (BiomimÃ©tica v2)

O projeto foi refatorado para eliminar acoplamento direto, utilizando um sistema de **Pub/Sub** global.

### 1. CÃ³rtex Frontal (OrquestraÃ§Ã£o & DecisÃ£o)
* **Orchestrator (`orchestrator.py`):** O "Gerente". Avalia intenÃ§Ãµes, gere a Janela de AtenÃ§Ã£o e decide se o input requer uma ferramenta, memÃ³ria ou conversa livre.
* **Hybrid Brain (`brain_llm.py`):** Motor de inferÃªncia com estratÃ©gia de **Fallback Inteligente**:
    1.  Tenta **Nuvem** (Groq/Llama-3.3-70b) para velocidade e precisÃ£o.
    2.  Em caso de falha/offline, assume **Local** (Ollama/Qwen/Llama3) automaticamente.
* **Event Bus (`event_bus.py`):** A "medula espinhal". Desacopla os sensores (Ouvido) dos atuadores (Fala/Apps), permitindo que o sistema "pense" sem bloquear a escuta.

### 2. Ãrea de Broca (Input/Output)
* **Listen (`listen.py`):**
    * Reconhecimento de fala via **Faster-Whisper** (Local).
    * Processamento de sinal com `numpy` e `noisereduce`.
    * **Intention Normalizer:** Filtra alucinaÃ§Ãµes do Whisper e aplica correÃ§Ãµes fonÃ©ticas aprendidas (MemÃ³ria de Reflexos).
* **Speak (`speak.py`):** SÃ­ntese de voz neural (Edge-TTS) e reproduÃ§Ã£o assÃ­ncrona.

### 3. Hipocampo (MemÃ³ria)
* **MemÃ³ria EpisÃ³dica (`memoria.py`):** Banco vetorial (**ChromaDB**) para armazenar factos e conversas de longo prazo (RAG - Retrieval Augmented Generation).
* **Reflexos (`reflexos.py`):** MemÃ³ria associativa rÃ¡pida para corrigir erros fonÃ©ticos recorrentes (ex: "tocasho" -> "tocar").

### 4. CÃ³rtex Motor (AÃ§Ã£o)
* **Launcher (`launcher.py`):** Indexador inteligente que varre o Menu Iniciar e localiza executÃ¡veis ou URIs (Spotify, Steam, URLs).
* **Agentes Especialistas:** MÃ³dulos de visÃ£o computacional (ex: Spotify Automation) e controlo de sistema.

---

## ğŸ› ï¸ Stack TecnolÃ³gico

* **Core:** Python 3.10+
* **Arquitetura:** Event-Driven (Pub/Sub Pattern)
* **IA & NLP:**
    * Nuvem: `groq` (Llama 3.3 Versatile)
    * Local: `ollama` (Qwen 2 / Llama 3)
    * STT: `faster-whisper` (Substituindo Vosk/SpeechRecognition)
* **Banco de Dados:** `chromadb` (Vector Store)
* **Ãudio:** `sounddevice` (Captura raw), `numpy`
* **VisÃ£o/AutomaÃ§Ã£o:** `opencv-python`, `pyautogui`

---

## ğŸ“‚ Estrutura do Projeto

```text
J.A.R.V.I.S/
â”‚
â”œâ”€â”€ main.py                     # Kernel: Bootstrap e InjeÃ§Ã£o de DependÃªncias
â”œâ”€â”€ requirements.txt            # DependÃªncias atualizadas
â”œâ”€â”€ .env                        # Credenciais (GROQ_API_KEY, etc.)
â”‚
â”œâ”€â”€ data/                       # PersistÃªncia
â”‚   â”œâ”€â”€ jarvis_memory_db/       # Banco de dados ChromaDB
â”‚   â””â”€â”€ speech_config.json      # ConfiguraÃ§Ãµes de Hotwords e Reflexos
â”‚
â””â”€â”€ jarvis_system/              # NÃºcleo Modular
    â”‚
    â”œâ”€â”€ protocol.py             # DefiniÃ§Ã£o de Contratos de Eventos
    â”‚
    â”œâ”€â”€ cortex_frontal/
    â”‚   â”œâ”€â”€ orchestrator.py     # LÃ³gica de Fluxo e AtenÃ§Ã£o
    â”‚   â”œâ”€â”€ brain_llm.py        # Gestor de LLMs (HÃ­brido)
    â”‚   â”œâ”€â”€ event_bus.py        # Barramento de Eventos (Pub/Sub)
    â”‚   â””â”€â”€ observability.py    # Sistema de Logs Coloridos
    â”‚
    â”œâ”€â”€ area_broca/
    â”‚   â”œâ”€â”€ listen.py           # Whisper Service + VAD
    â”‚   â””â”€â”€ speak.py            # TTS Service
    â”‚
    â”œâ”€â”€ hipocampo/
    â”‚   â”œâ”€â”€ memoria.py          # Interface ChromaDB
    â”‚   â””â”€â”€ reflexos.py         # Aprendizado RÃ¡pido
    â”‚
    â””â”€â”€ cortex_motor/
        â”œâ”€â”€ launcher.py         # Indexador de Apps e Web
        â””â”€â”€ tool_registry.py    # Registro de Ferramentas

ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o
1. PrÃ©-requisitos
Python 3.10 ou superior.

Ollama instalado e rodando (para modo offline/fallback).

Chave de API da Groq.

2. Setup do Ambiente

# Clone o repositÃ³rio
git clone [https://github.com/seu-usuario/jarvis-v2.git](https://github.com/seu-usuario/jarvis-v2.git)
cd jarvis-v2

# Crie o ambiente virtual
python -m venv .venv

# Ative o ambiente
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

# Instale as dependÃªncias
pip install -r requirements.txt

3. ConfiguraÃ§Ã£o (.env)
Crie um arquivo .env na raiz:

GROQ_API_KEY=gsk_sua_chave_aqui
JARVIS_MODEL_CLOUD=llama-3.3-70b-versatile
JARVIS_MODEL_LOCAL=qwen2:0.5b

4. ExecuÃ§Ã£o
python main.py

ğŸ® Funcionalidades e Comandos
Modo HÃ­brido: Se a internet cair, o Jarvis avisa e muda para o modelo local (Ollama).

MemÃ³ria Viva: "Jarvis, memorize que o cÃ³digo do portÃ£o Ã© 1234".

RecuperaÃ§Ã£o (RAG): "Qual Ã© o cÃ³digo do portÃ£o?" (Busca no ChromaDB).

Aprendizado Ativo: Se ele entender errado, diga: "Aprenda que 'tocasho' significa 'tocar'". Ele guardarÃ¡ isso nos reflexos.

Apps: "Abrir Spotify", "Abrir VS Code", "Tocar 30PRAUM" (Spotify Agent).

âš ï¸ SoluÃ§Ã£o de Problemas
Erro de Ãudio (PortAudio): Se houver erro no sounddevice, verifique se o driver de microfone estÃ¡ definido como padrÃ£o no Windows.

MemÃ³ria Offline: Se o ChromaDB falhar, o sistema inicia em modo "AmnÃ©sia" (apenas reativo).

Whisper Lento: A primeira execuÃ§Ã£o baixa o modelo (~500MB). As seguintes sÃ£o instantÃ¢neas.


### Principais AlteraÃ§Ãµes Realizadas:

1.  **AtualizaÃ§Ã£o da Ãrvore de Arquivos:** Reflete a nova organizaÃ§Ã£o em `jarvis_system/` com a separaÃ§Ã£o clara entre `cortex_frontal`, `area_broca`, etc.
2.  **Destaque ao Event Bus:** Documentei a mudanÃ§a crucial para uma arquitetura orientada a eventos, que nÃ£o existia na versÃ£o anterior.
3.  **CÃ©rebro HÃ­brido:** Adicionei a explicaÃ§Ã£o sobre o fallback entre Groq (Nuvem) e Ollama (Local), presente no cÃ³digo `brain_llm.py`.
4.  **MemÃ³ria & Reflexos:** Detalhei o uso do `ChromaDB` e a funcionalidade de correÃ§Ã£o fonÃ©tica dinÃ¢mica (Reflexos) encontrada em `listen.py` e `reflexos.py`.
5.  **SubstituiÃ§Ã£o de Bibliotecas:** Removi referÃªncias a `PyAudio` e `SpeechRecogn