# jarvis_system/cortex_frontal/orchestrator/orchestrator.py
import time
import re
import random
import asyncio
from typing import Optional

from jarvis_system.cortex_frontal.observability import JarvisLogger
from jarvis_system.cortex_frontal.event_bus import bus, Evento
from jarvis_system.protocol import Eventos

# Depend√™ncias Globais
try:
    from jarvis_system.cortex_motor.tool_registry import registry
    from jarvis_system.cortex_motor.appLauncher import launcher 
    from jarvis_system.cortex_frontal.brain_llm import llm 
    from jarvis_system.cortex_frontal.curiosityEngine import curiosity
    from jarvis_system.hipocampo.reflexos import reflexos
except ImportError:
    registry, launcher, llm, curiosity, reflexos = None, None, None, None, None

# M√≥dulos Locais
from .configOrchestrator import CONFIRMATION_YES, CONFIRMATION_NO
from .attentionSystem import AttentionSystem
from .learningHandler import LearningHandler
from .toolsHandler import ToolsHandler
from .cognitionHandler import CognitionHandler

class Orchestrator:
    def __init__(self):
        self.log = JarvisLogger("CORTEX_FRONTAL")
        
        # Subsistemas
        self.attention = AttentionSystem()
        self.learner = LearningHandler(reflexos)
        self.tools = ToolsHandler(launcher, registry)
        self.cognitive = CognitionHandler(llm, curiosity)
        
        self.pending_context: Optional[dict] = None
        
        # Barramento
        bus.inscrever(Eventos.FALA_RECONHECIDA, self.process_input)
        self.log.info("üß† C√≥rtex Frontal (Modular v4.0) Instanciado.")

    # -------------------------------------------------------------------------
    # üïµÔ∏è‚Äç‚ôÇÔ∏è VERIFICA√á√ÉO REAL DO ESTADO (A CORRE√á√ÉO)
    # -------------------------------------------------------------------------
    @property
    def sistemas_carregados(self) -> bool:
        return True

    # -------------------------------------------------------------------------

    def process_input(self, evento: Evento):
        raw_text = evento.dados.get("texto", "")
        if not raw_text: return
        
        # üö® LOG DE DEBUG: Vamos ver se o Orquestrador pelo menos acorda!
        self.log.info(f"üì• Chegou no Orquestrador: '{raw_text}'")

        # Ignora comandos se o sistema ainda n√£o estiver 100% carregado
        if not self.sistemas_carregados:
            self.log.warning("‚ö†Ô∏è Comando ignorado! A trava 'sistemas_carregados' est√° bloqueando (menos de 3 agentes no Registry).")
            return

        # 1. Normaliza√ß√£o B√°sica
        clean_text = re.sub(r'[^\w\s]', '', raw_text.lower()).strip()
        clean_text = re.sub(r'(.)\1{2,}', r'\1', clean_text) 

        # 2. Confirma√ß√µes Pendentes
        if self._handle_confirmation(clean_text): return

        # 3. Aten√ß√£o (Wake Word)
        is_active, payload = self.attention.check(clean_text)
        
        if not is_active: 
            self.log.warning(f"‚ö†Ô∏è Comando ignorado! A palavra de ativa√ß√£o (Jarvis) n√£o foi validada em: '{clean_text}'")
            return

        if not payload:
            self._speak(random.choice(["Pois n√£o?", "Estou aqui.", "Sim?", "√Äs ordens."]))
            return

        self.log.info(f"ü§î Processando: '{payload}'")

        # 4. Pipeline de Execu√ß√£o
        try:
            # 4.1 Aprendizado R√°pido
            ok, msg = self.learner.handle(payload)
            if ok:
                self._speak(msg)
                return

            # 4.2 Comandos Diretos
            ok, msg = self.tools.handle_direct_command(payload)
            if ok:
                self._speak(msg)
                return

            # 4.3 Cogni√ß√£o (LLM)
            response_text, json_action = self.cognitive.process(payload)
            
            if json_action:
                self._execute_json_action(json_action)
            elif response_text:
                self._speak(response_text)

        except Exception as e:
            self.log.error(f"Erro no pipeline: {e}")
            self._speak("Ocorreu um erro interno no processamento.")

    def _handle_confirmation(self, text: str) -> bool:
        if not self.pending_context: return False
        
        words = text.split()
        if any(w in words for w in CONFIRMATION_YES):
            self._execute_pending()
            return True
        elif any(w in words for w in CONFIRMATION_NO):
            self._speak("Cancelado.")
            self.pending_context = None
            return True
        return False

    def _execute_pending(self):
        ctx = self.pending_context
        if ctx["type"] == "app_suggestion":
            self._speak(f"Abrindo {ctx['name']}.")
            if launcher: launcher.abrir_por_caminho(ctx["path"])
            if reflexos: 
                reflexos.adicionar_correcao(ctx["original_term"], ctx["name"].lower())
        self.pending_context = None

    class DependencyNode:
        """Estrutura do TaskBench para n√≥s do Grafo (DAG)."""
        def __init__(self, task_id, target_tool, initial_args, dependencies):
            self.task_id = task_id
            self.target_tool = target_tool
            self.initial_args = initial_args
            self.dependencies = dependencies
            self.output_data = None
            self.completion_event = asyncio.Event() # Cadeado ass√≠ncrono

    def _execute_json_action(self, action_data):
        """
        FASE 2: Motor de Execu√ß√£o de Grafos (DAG).
        L√™ a lista de tarefas, mapeia depend√™ncias e dispara tudo em paralelo.
        """
        # 1. Normaliza√ß√£o (Aceita o DAG novo ou o dicion√°rio antigo como fallback)
        tasks = action_data if isinstance(action_data, list) else [action_data]
        nodes = []

        # 2. Constr√≥i os N√≥s do Grafo
        for t in tasks:
            if "ferramenta" in t: # Fallback para o modo antigo (dict)
                nodes.append(self.DependencyNode("t1", t.get("ferramenta"), {k: v for k, v in t.items() if k != "ferramenta"}, []))
            else: # Novo modo Grafo DAG
                nodes.append(self.DependencyNode(
                    t.get("task_id", f"task_{random.randint(0,999)}"),
                    t.get("target_tool"),
                    t.get("initial_args", {}),
                    t.get("dependencies", [])
                ))

        self.log.info(f"üï∏Ô∏è Grafo de Tarefas (DAG) montado com {len(nodes)} n√≥(s). Executando...")

        # 3. L√≥gica Ass√≠ncrona de Paralelismo
        async def process_single_node(node, all_nodes):
            # A) Aguardar as depend√™ncias terminarem primeiro
            for dep_id in node.dependencies:
                dep_node = next((n for n in all_nodes if n.task_id == dep_id), None)
                if dep_node:
                    self.log.info(f"‚è≥ N√≥ '{node.task_id}' aguardando n√≥ '{dep_id}' terminar...")
                    await dep_node.completion_event.wait()

            # B) Executar a Ferramenta
            self.log.info(f"üöÄ Disparando N√≥ '{node.task_id}' -> Ferramenta: '{node.target_tool}'")
            try:
                if node.target_tool == "memoria_gravar":
                    dado = node.initial_args.get("dado") or node.initial_args.get("parametro")
                    if llm: llm.ensinar(dado)
                    node.output_data = f"Memorizado: {dado}"
                else:
                    node.output_data = self.tools.execute_tool_from_llm(node.target_tool, **node.initial_args)
            except Exception as e:
                node.output_data = f"Erro na tarefa {node.task_id}: {e}"

            # C) Destrancar o cadeado (Avisa quem estava esperando que terminou)
            self.log.info(f"‚úÖ N√≥ '{node.task_id}' conclu√≠do.")
            node.completion_event.set()

        async def execute_graph():
            # Inicia TODOS os n√≥s ao mesmo tempo. Os que t√™m depend√™ncias v√£o pausar sozinhos.
            await asyncio.gather(*(process_single_node(n, nodes) for n in nodes))

        # 4. Inicia o Loop Ass√≠ncrono para resolver o Grafo
        asyncio.run(execute_graph())

        # 5. Fala os resultados processados para o usu√°rio
        for n in nodes:
            if n.output_data and str(n.output_data).strip() and str(n.output_data) != "None":
                self._speak(str(n.output_data))

    def _speak(self, text: str):
        bus.publicar(Evento(Eventos.FALAR, {"texto": text}))

    def start(self):
        # Apenas logamos. A propriedade 'sistemas_carregados' agora faz a verifica√ß√£o real
        # dinamicamente sempre que a API perguntar.
        self.log.info("üß† C√≥rtex Frontal iniciado (Aguardando especialistas...).")

    def stop(self):
        pass