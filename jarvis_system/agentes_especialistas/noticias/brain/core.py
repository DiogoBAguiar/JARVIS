import logging
import json
import re
from ..tools.search_engine import NewsEngine

# --- INTEGRA칂츾O COM AGNO LOCAL (NOT칈CIAS) ---
# Usa a f치brica local que criamos para n칚o depender de arquivos globais por enquanto
try:
    from .llm_setup_noticias import LLMFactory 
    from agno.agent import Agent
except ImportError:
    LLMFactory = None
    Agent = None

logger = logging.getLogger("NEWS_BRAIN")

class NewsBrain:
    def __init__(self):
        self.engine = NewsEngine()
        self.agent_llm = None
        
        # Inicializa o LLM via F치brica Local
        self._setup_llm()

        self.mapa_categorias = {
            "futebol": "futebol", "bola": "futebol", "jogo": "futebol", "flamengo": "futebol",
            "esporte": "esporte", "esportes": "esporte",
            "tech": "tecnologia", "tecnologia": "tecnologia", "celular": "tecnologia", "ia": "tecnologia",
            "crypto": "crypto", "bitcoin": "crypto", "cripto": "crypto",
            "economia": "economia", "dolar": "economia", "bolsa": "economia",
            "brasil": "geral", "geral": "geral", "manchetes": "geral", "noticias": "geral", "not칤cias": "geral",
            "paraiba": "paraiba", "joao pessoa": "paraiba", "local": "paraiba"
        }

    def _setup_llm(self):
        """Configura o Agente Agno usando o modelo local."""
        if LLMFactory and Agent:
            model = LLMFactory.get_model("llama-3.3-70b-versatile")
            if model:
                self.agent_llm = Agent(
                    model=model,
                    description="Voc칡 칠 um 칙ncora de jornal experiente, objetivo e natural.",
                    markdown=False
                )
            else:
                logger.warning("丘멆잺 F치brica n칚o retornou modelo (verifique API KEYs).")

    def processar_solicitacao(self, user_input: str) -> str:
        # 1. LIMPEZA PRELIMINAR
        termo_clean = self._limpar_texto(user_input)
        
        # 2. ROTEAMENTO: RSS vs BUSCA
        categoria_detectada = self._detectar_categoria(termo_clean)
        
        noticias_raw = []
        modo = ""

        if categoria_detectada:
            logger.info(f"游 Rota definida: RSS ({categoria_detectada})")
            noticias_raw = self.engine.get_briefing(categoria=categoria_detectada)
            modo = "briefing"
        else:
            # Limpeza cir칰rgica para busca
            termo_busca = self._limpar_para_busca(user_input)
            logger.info(f"游 Rota definida: BUSCA WEB ('{termo_busca}')")
            
            if len(termo_busca) < 3:
                return "Senhor, preciso de um tema mais espec칤fico para pesquisar."
                
            noticias_raw = self.engine.search_topic(termo_busca)
            modo = "investigacao"

        if not noticias_raw:
            return "Desculpe, senhor. Minhas fontes n칚o retornaram nada relevante sobre isso no momento."

        # 3. S칈NTESE
        return self._sintetizar_com_llm(noticias_raw, modo, user_input)

    def _limpar_texto(self, texto):
        """Remove pontua칞칚o e deixa min칰sculo."""
        return re.sub(r'[^\w\s]', '', texto.lower())

    def _limpar_para_busca(self, texto):
        """Remove stopwords para busca eficiente."""
        stopwords = ["jarvis", "o que", "quais", "as", "os", "novidades", "noticias", "sobre", "a", "e", "do", "da", "em", "recentemente", "hoje", "agora", "lancou"]
        palavras = self._limpar_texto(texto).split()
        palavras_uteis = [p for p in palavras if p not in stopwords]
        return " ".join(palavras_uteis)

    def _detectar_categoria(self, texto_limpo):
        tokens = texto_limpo.split()
        for token in tokens:
            if token in self.mapa_categorias:
                return self.mapa_categorias[token]
        return None

    def _sintetizar_com_llm(self, dados, modo, topico_original):
        """Gera o prompt e envia para o Agno."""
        
        # Fallback se Agno n칚o estiver ativo
        if not self.agent_llm:
            return f"Simula칞칚o (Offline): Encontrei {len(dados)} not칤cias. Manchete: {dados[0].get('titulo')}"

        contexto_dados = json.dumps(dados, indent=2, ensure_ascii=False)
        
        if modo == "briefing":
            instrucao = "O usu치rio pediu um resumo r치pido. Crie um texto curto (m치ximo 3 frases) conectando as not칤cias. Seja natural."
        else:
            instrucao = f"O usu치rio perguntou sobre: '{topico_original}'. Explique o contexto com base nos dados abaixo. Seja direto."

        prompt_final = f"""
        INSTRU칂츾O: {instrucao}
        DADOS RECEBIDOS: {contexto_dados}
        SA칈DA (Texto puro em PT-BR para TTS):
        """
        
        try:
            # Agno executa e retorna o objeto RunResponse
            response = self.agent_llm.run(prompt_final)
            return response.content
        except Exception as e:
            logger.error(f"Erro no LLM: {e}")
            return "Tive um problema ao gerar o resumo das not칤cias, senhor."